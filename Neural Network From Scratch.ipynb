{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Declare Activation and Activation Derivative functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    y=1/(1+np.exp(-x))\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid_derivative(x):\n",
    "    return sigmoid(x)*(1-sigmoid(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Forward Pass Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#forward pass\n",
    "def forward_pass(X):\n",
    "    global network_architecture,Z,A,Z_temp,A_temp\n",
    "    \n",
    "    Z=[]\n",
    "    A=[]\n",
    "    Z_temp=np.array([0])\n",
    "    A_temp=np.array(X)\n",
    "    Z.append(Z_temp)\n",
    "    A.append(A_temp)\n",
    "    \n",
    "    for i in range(len(network_architecture)-1):\n",
    "        Z_temp=np.dot(W[i].T,A[i])+B[i]\n",
    "        A_temp=sigmoid(Z_temp)\n",
    "        Z.append(Z_temp)\n",
    "        A.append(A_temp)\n",
    "    #Convert List to np.array    \n",
    "    A=np.array(A,dtype=object)\n",
    "    Z=np.array(Z,dtype=object)\n",
    "    return A[len(A)-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Backward Pass Function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward_pass(alfa,epoch,n_epochs):\n",
    "    global X,y,A,Z,W,B,G\n",
    "    #Because Gradients of the First and the last layers have specific formulas I calculate them\n",
    "    #before and after the for cycle.\n",
    "\n",
    "    #Calculate Gradients of Last layer parameters\n",
    "    L=len(A)\n",
    "    dZ=A[L-1]-y\n",
    "    dW=np.dot(A[L-2],dZ.T)\n",
    "    dB=(1/m)*np.sum(dZ,axis=1,keepdims=True)\n",
    "    dA=np.dot(W[L-2],dZ)\n",
    "   \n",
    "    #Update Last Layer parameters\n",
    "    W[L-2]=W[L-2]-alfa*dW\n",
    "    B[L-2]=B[L-2]-alfa*dB\n",
    "    if(epoch==(n_epochs-1)):\n",
    "        print(\"Gradients of Last Hidden Layer :\",alfa*dW)\n",
    "    #Calculate and update of  Gradients of Last-1 layer to Input_layer+1 layer\n",
    "\n",
    "    for j in range(L-3,0,-1):\n",
    "        dZ=np.multiply(dA,sigmoid_derivative(Z[j+1]))\n",
    "        dW=np.dot(A[j],dZ.T)\n",
    "        dB=(1/m)*np.sum(dZ,axis=1,keepdims=True)\n",
    "        dA=np.dot(W[j],dZ)\n",
    "\n",
    "        W[j]=W[j]-alfa*dW\n",
    "        B[j]=B[j]-alfa*dB\n",
    "        if(epoch==(n_epochs-1)):\n",
    "            print(\"Gradients of \",j+1,\"-thHidden Layer :\",alfa*dW)\n",
    "    \n",
    "    #Calculate Gradients of First layer parameters\n",
    "    dZ=np.multiply(dA,sigmoid_derivative(Z[1]))    \n",
    "    dW=np.dot(A[0],dZ.T)\n",
    "    dB=(1/m)*np.sum(dZ,axis=1,keepdims=True)\n",
    "\n",
    "    #Update First Layer parameters\n",
    "    \n",
    "    W[0]=W[0]-alfa*dW\n",
    "    B[0]=B[0]-alfa*dB\n",
    "    if(epoch==(n_epochs-1)):\n",
    "        print(\"Gradients of 1-st Hidden Layer :\",alfa*dW)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Training set\n",
    "X=np.array([[0.1, 0.2, 0.3], [0.4, 0.5, 0.4],[0.5,0.6,0.7],[0.6,0.7,0.8],[0.7,0.8,0.9],[0.8,0.0,1.0]])\n",
    "X=X.T\n",
    "y=np.array([[0,1,1,1,1,1]])\n",
    "\n",
    "# Number of Training instances\n",
    "m=X.shape[1]\n",
    "#Number of inputs\n",
    "number_of_inputs=X.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Neural Network Hyper Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Neural Network architecture\n",
    "network_architecture=[number_of_inputs,2,4,8,1]\n",
    "#Learning reate\n",
    "alfa=0.1\n",
    "#Number of epochs\n",
    "n_epochs=10000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialise Weights,Biases and Cache arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Infer W and b matrix sizes from network architecrure and initialisze with random values.\n",
    "W=[]\n",
    "B=[]\n",
    "W_temp=np.random.rand(network_architecture[0],network_architecture[1])\n",
    "B_temp=np.random.rand(network_architecture[1],1)\n",
    "\n",
    "W.append(W_temp)\n",
    "B.append(B_temp)\n",
    "for i in range(1,len(network_architecture)-1):\n",
    "    W_temp=np.random.rand(network_architecture[i],network_architecture[i+1])\n",
    "    B_temp=np.random.rand(network_architecture[i+1],1)\n",
    "\n",
    "    W.append(W_temp)\n",
    "    B.append(B_temp)\n",
    "#Convert List to np.array    \n",
    "W=np.array(W,dtype=object)\n",
    "B=np.array(B,dtype=object)    \n",
    "\n",
    "\n",
    "#Initialize Z(Weighted sum+bias) and A(g(Z)) cache  arrays. They are needed for calculating the gradients\n",
    "Z=[]\n",
    "A=[]\n",
    "Z_temp=np.array([0])\n",
    "A_temp=np.array(X)\n",
    "Z.append(Z_temp)\n",
    "A.append(A_temp)\n",
    "\n",
    "# Variable To store gradients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradients of Last Hidden Layer : [[ 3.87688745e-05]\n",
      " [ 4.06891405e-05]\n",
      " [ 3.93488144e-05]\n",
      " [-9.41826836e-05]\n",
      " [-1.93739710e-05]\n",
      " [ 4.78059435e-05]\n",
      " [-8.58154877e-05]\n",
      " [-1.05571195e-04]]\n",
      "Gradients of  3 -thHidden Layer : [[-5.47029483e-06 -3.37300619e-06 -4.35049890e-06  1.78021638e-05\n",
      "   1.48314632e-05 -3.60879897e-06  1.75622369e-05  1.58693327e-05]\n",
      " [ 5.70875452e-06  2.20604910e-05  5.99873214e-06 -5.79903467e-05\n",
      "  -2.07300077e-05  4.01404240e-05 -5.76599136e-05 -4.95751683e-05]\n",
      " [-4.83055996e-06 -1.24210496e-06 -3.70438926e-06  1.22162090e-05\n",
      "   1.26192229e-05  2.12912108e-07  1.19778824e-05  1.11364263e-05]\n",
      " [-4.20215837e-06 -1.43734194e-06 -3.25090127e-06  1.12998309e-05\n",
      "   1.10721416e-05 -5.11561410e-07  1.11064551e-05  1.02247359e-05]]\n",
      "Gradients of  2 -thHidden Layer : [[-1.59806554e-05  4.42032613e-05 -1.48655193e-05 -1.59342150e-05]\n",
      " [ 3.48069310e-05 -3.01502533e-05  1.43835411e-05  1.79499786e-05]]\n",
      "Gradients of 1-st Hidden Layer : [[ 3.51390666e-05 -2.12336238e-05]\n",
      " [ 2.51537292e-05 -1.37047480e-05]\n",
      " [ 1.03265040e-05  5.98143613e-06]]\n"
     ]
    }
   ],
   "source": [
    "#After Training the network Last Value of weights Gradients will be printed. I print Gradients to observe Vanishing Gradients\n",
    "# Problem On Large Nets( Nets with more that 4 hidden Layer).\n",
    "for i in range(n_epochs):\n",
    "    forward_pass(X)\n",
    "    backward_pass(alfa,i,n_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00167034, 0.99946682, 0.99979344, 0.9998293 , 0.99984431,\n",
       "        0.99980735]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forward_pass(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
